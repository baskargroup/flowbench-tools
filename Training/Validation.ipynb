{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d48c1a-f1db-458b-b820-4ec22058e6c9",
   "metadata": {},
   "source": [
    "# Importing the Library\n",
    "1. `from codes.utils.device import device` returns `CUDA` is NVIDIA GPU is available for computation else returns `CPU` if NVIDIA is not available\n",
    "2. `from codes.models.FNO import TensorizedFNO` is used to load trained FNO models for inference\n",
    "3. `from codes.models.CNO import CompressedCNO` is used to load trained CNO models for inference\n",
    "4. `from codes.data.dataset import LidDrivenDataset` is used to load datasets from `npz` format for `x` and `y` mappings for the model\n",
    "5. `from codes.utils.visualization import plot_ldc_like` is used to plot the `y`, `y_predicted` and `|y_predicted - y|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460c2ebc-519d-4b7a-b0ed-1ffa1e913f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA for tensor operations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from codes.utils.device import device\n",
    "from codes.models.FNO import TensorizedFNO\n",
    "from codes.models.CNO import CompressedCNO\n",
    "from codes.data.dataset import LidDrivenDataset\n",
    "from codes.utils.visualization import plot_ldc_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdccd83-cf59-40be-81be-c88b3a0708c8",
   "metadata": {},
   "source": [
    "# Defining the function to read the configuration YAML file\n",
    "This function would read the `file_name` YAML file located in the folder `folder_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72355448-ac75-4b5d-8834-c7372fc4f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml_file(folder_path, file_name):\n",
    "    \"\"\"Reads a YAML file and returns the data.\"\"\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            data = yaml.safe_load(file)\n",
    "            return data\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(f\"Error reading YAML file: {exc}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86e115-2472-4a76-ae1b-2fc0779603f5",
   "metadata": {},
   "source": [
    "# Defining the function to calculate the different type of Mean Square Error\n",
    "### Define further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "315c3492-3b2c-4d15-b20e-d8e2612e440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics_validation_set(y, yhat, resolution):\n",
    "\n",
    "  half_res = int(resolution/2)\n",
    "\n",
    "  mse = nn.MSELoss()\n",
    "\n",
    "  mses = torch.zeros(7) # we are outputing 7 validation metrics\n",
    "\n",
    "  #mse full\n",
    "  mses[0] = mse(y,yhat)\n",
    "\n",
    "  #mse u,v\n",
    "  mses[1] = mse(y[:,0:2,:,:], yhat[:,0:2,:,:])\n",
    "\n",
    "  #mse p\n",
    "  mses[2] = mse(y[:,2,:,:], yhat[:,2,:,:])\n",
    "\n",
    "  #mse near object u, v\n",
    "  if resolution == 128:\n",
    "    mses[3] = mse(y[:,0:2,25:104,25:104], yhat[:,0:2,25:104,25:104])\n",
    "  elif resolution == 256:\n",
    "    mses[3] = mse(y[:,0:2,51:206,51:206], yhat[:,0:2,51:206,51:206])\n",
    "  else:\n",
    "    mses[3] = mse(y[:,0:2,102:410,102:410], yhat[:,0:2,102:410,102:410])\n",
    "\n",
    "  #mse near object p\n",
    "  if resolution == 128:\n",
    "    mses[4] = mse(y[:,2,25:104,25:104], yhat[:,2,25:104,25:104])\n",
    "  elif resolution == 256:\n",
    "    mses[4] = mse(y[:,2,51:206,51:206], yhat[:,2,51:206,51:206])\n",
    "  else:\n",
    "    mses[4] = mse(y[:,2,102:410,102:410], yhat[:,2,102:410,102:410])\n",
    "\n",
    "  #mse cd\n",
    "  mses[5] = mse(y[:,3,:half_res,:], yhat[:,3,:half_res,:])\n",
    "\n",
    "  #mse cl\n",
    "  mses[6] = mse(y[:,3,half_res:,:], yhat[:,3,half_res:,:])\n",
    "  \n",
    "  #return\n",
    "  return mses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800fc6aa-ffde-456f-8e0c-957e0a6f69a7",
   "metadata": {},
   "source": [
    "# Determine the path to the model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2783746-5675-44b4-9c24-ffc03436ee7f",
   "metadata": {},
   "source": [
    "First we would locate the weights and the location of the configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c48e6e7-2708-4049-a01a-d9e38abcb5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cno_1  fno_1\n"
     ]
    }
   ],
   "source": [
    "!ls experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc732e-b1f6-4e71-9cf1-1640219044f1",
   "metadata": {},
   "source": [
    "We would like to run inference for CNO. So we will use the folder `cno_1`. The confugaration file found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c707ce-c3e0-40ba-8b8d-c408e1e9f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints  config.yaml  dataset  log.txt  plots\n"
     ]
    }
   ],
   "source": [
    "!ls experiments/cno_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981d02f-ce81-433e-a361-6b9d53872f27",
   "metadata": {},
   "source": [
    "Checkpoint files are found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5001da4f-08cf-46ce-bd2e-c96994159516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.pth  200.pth  300.pth  400.pth\n"
     ]
    }
   ],
   "source": [
    "!ls experiments/cno_1/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a905eaf-f72d-4150-bb1e-44b50be37489",
   "metadata": {},
   "source": [
    "The configuration data is imported. This configuration file is used to define the CNO Model that would be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94a19b5-8179-476a-84d6-d9322b6c838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = read_yaml_file('experiments/cno_1/', \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c28a8-4ad8-4186-9858-98e0893519b3",
   "metadata": {},
   "source": [
    "# Loading the weights of 400th Epoch of the trained CNO Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de41b5-7503-417e-bfcc-70c26e06401f",
   "metadata": {},
   "source": [
    "We would want to clear the cache in the cuda before loading the model if NVIDIA GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7482c66c-e432-462e-a90a-e89f5cd88970",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a108f-428b-4020-907b-18b8088b2b2d",
   "metadata": {},
   "source": [
    "Initializing the model using the configuration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48051778-39df-487d-9138-65b7d35dd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNO_trained= CompressedCNO(in_dim = config_data['in_dim'], out_dim = config_data['out_dim'], \n",
    "                          N_layers = config_data['N_layers'], in_size = config_data['in_size'], \n",
    "                          out_size = config_data['out_size']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb579d7-03b0-4d27-8da8-a0b08cedc5e8",
   "metadata": {},
   "source": [
    "Loading the checkpoint into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0054f904-06fc-40f1-ace0-5886d0e755e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNO_trained.load_checkpoint(save_name=\"400\", save_folder='experiments/cno_1/checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb04dab-a7fa-4a72-a3fe-8c7373bbfc6b",
   "metadata": {},
   "source": [
    "# Loading the dataset from the `npz` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24628948-dba4-481e-9b07-dc773c71465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_npz = LidDrivenDataset(file_path_x= config_data['file_path_x'], \n",
    "                           file_path_y = config_data['file_path_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf2cd7-0f76-41a6-aadb-a23527ef447c",
   "metadata": {},
   "source": [
    "# Loading the dataset from the `pt` files saved during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0813aa-1746-496c-a304-fb850ed49c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pt = torch.load('experiments/cno_1/dataset/val.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb3502-d711-4f03-8174-b1f43536976d",
   "metadata": {},
   "source": [
    "# Performing MSE Calculations with the `dataset_pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43eb504-f289-4e2e-8ba0-4bd67a380d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "CNO_trained.eval()\n",
    "\n",
    "# Disable gradient calculation to save memory and speed up computations\n",
    "with torch.no_grad():\n",
    "    # Initialize a tensor to store the sum of MSEs for each output\n",
    "    sum_mse = torch.zeros(7)\n",
    "    \n",
    "    # Create a data loader for the validation set\n",
    "    val_loader = torch.utils.data.DataLoader(dataset_pt, batch_size=5, shuffle=True)\n",
    "    \n",
    "    # Iterate over batches in the validation set\n",
    "    for batch in val_loader:\n",
    "        # Move the input and target tensors to the device (e.g., GPU)\n",
    "        inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        # Pass the inputs through the model to get the outputs\n",
    "        outputs = CNO_trained.forward(inputs)\n",
    "        \n",
    "        # Calculate the MSE for each output using the all_metrics_validation_set function\n",
    "        mses = all_metrics_validation_set(targets, outputs, 128)\n",
    "        \n",
    "        # Accumulate the MSEs for each output\n",
    "        sum_mse += mses\n",
    "    \n",
    "    # Calculate the average MSE for each output by dividing the sum by the total number of samples\n",
    "    calculated_mse = sum_mse / len(val_loader.dataset)\n",
    "\n",
    "# Print the configuration data and the calculated MSEs\n",
    "print(\"The Confugaration for CNO:\", '\\n', config_data, '\\n \\n', \"Calculated MSE:\", '\\n', calculated_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802616f4-18d9-4397-a704-40d6fd608d5a",
   "metadata": {},
   "source": [
    "# Ploting the `y`, `y_predicted` and `|y_predicted - y|` with   MSE Calculations with the `npz` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55efaf8-1922-4100-b882-4e31c9287b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "CNO_trained.eval()\n",
    "\n",
    "# Disable gradient calculation to save memory and speed up computations\n",
    "with torch.no_grad():\n",
    "    # We will use the dataset with the index 10 for this computation.\n",
    "    id = 10\n",
    "    \n",
    "    # Retrieve input data and targets from the dataset\n",
    "    inputs, targets = dataset_npz[id]\n",
    "    \n",
    "    # Perform a forward pass through the model\n",
    "    outputs = CNO_trained.forward(inputs.unsqueeze(0).to(device))\n",
    "    \n",
    "    # Visualize the output and save it in the folder `experiments/cno_1/plots` with the name `CNO_1_{id}.png`\n",
    "    plot_ldc_like(targets.unsqueeze(0).cpu().numpy(), \n",
    "                  outputs.cpu().numpy(), 0, \n",
    "                  os.path.join('experiments/cno_1/plots', f'CNO_1_{id}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488ebb2-912d-41b9-a30a-54e03118a96d",
   "metadata": {},
   "source": [
    "# The Plot have been saved at `experiments/cno_1/plots/CNO_1_10.png`\n",
    "![CNO Output](experiments/cno_1/plots/CNO_1_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40690c8-5f9d-4a40-8385-733192620415",
   "metadata": {},
   "source": [
    "# Repeating for FNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051670b0-3437-40d4-9aa3-276f0ad3325d",
   "metadata": {},
   "source": [
    "Calculating the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311b0af-117b-4e39-a5e6-a22ac75aca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release any unoccupied cached memory on the GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Read configuration data from a YAML file\n",
    "config_data = read_yaml_file('experiments/fno_1', \"config.yaml\")\n",
    "\n",
    "# Create an instance of the FNO model with configuration parameters\n",
    "FNO_trained = TensorizedFNO(n_modes=config_data['n_modes'], in_channels=config_data['in_channels'], \n",
    "                             out_channels=config_data['out_channels'], hidden_channels=config_data['hidden_channels'], \n",
    "                             projection_channels=config_data['projection_channels'], n_layers=config_data['n_layers']).to(device)\n",
    "\n",
    "# Load a pre-trained checkpoint for the FNO model\n",
    "FNO_trained.load_checkpoint(save_name=\"400\", save_folder='experiments/fno_1/checkpoints')\n",
    "\n",
    "# Create an instance of the LidDrivenDataset with the data loaded in it\n",
    "dataset_npz = LidDrivenDataset(file_path_x=config_data['file_path_x'], \n",
    "                               file_path_y=config_data['file_path_y'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "FNO_trained.eval()\n",
    "\n",
    "# Disable gradient calculation to save memory and speed up computations\n",
    "with torch.no_grad():\n",
    "    # Initialize a tensor to store the sum of MSEs for each output\n",
    "    sum_mse = torch.zeros(7)\n",
    "    \n",
    "    # Create a data loader for the validation set\n",
    "    val_loader = torch.utils.data.DataLoader(dataset_npz, batch_size=5, shuffle=True)\n",
    "    \n",
    "    # Iterate over batches in the validation set\n",
    "    for batch in val_loader:\n",
    "        # Move the input and target tensors to the device (e.g., GPU)\n",
    "        inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        # Pass the inputs through the model to get the outputs\n",
    "        outputs = FNO_trained.forward(inputs)\n",
    "        \n",
    "        # Calculate the MSE for each output using the all_metrics_validation_set function\n",
    "        mses = all_metrics_validation_set(targets, outputs, 128)\n",
    "        \n",
    "        # Accumulate the MSEs for each output\n",
    "        sum_mse += mses\n",
    "    \n",
    "    # Calculate the average MSE for each output by dividing the sum by the total number of samples\n",
    "    calculated_mse = sum_mse / len(val_loader.dataset)\n",
    "\n",
    "# Print the configuration data and the calculated MSEs\n",
    "print(\"The Confugaration for CNO:\", '\\n', config_data, '\\n \\n', \"Calculated MSE:\", '\\n', calculated_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b48db9-3564-4aa7-8be1-0fcdf7c25cbd",
   "metadata": {},
   "source": [
    "Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e110f51-38d8-4be9-882e-15d49da42675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "FNO_trained.eval()\n",
    "\n",
    "# Disable gradient calculation to save memory and speed up computations\n",
    "with torch.no_grad():\n",
    "    # We will use the dataset with the index 10 for this computation.\n",
    "    id = 10\n",
    "    \n",
    "    # Retrieve input data and targets from the dataset\n",
    "    inputs, targets = dataset_npz[id]\n",
    "    \n",
    "    # Perform a forward pass through the model\n",
    "    outputs = FNO_trained.forward(inputs.unsqueeze(0).to(device))\n",
    "    \n",
    "    # Visualize the output and save it in the folder `experiments/fno_1/plots` with the name `FNO_1_{id}.png`\n",
    "    plot_ldc_like(targets.unsqueeze(0).cpu().numpy(), \n",
    "                  outputs.cpu().numpy(), 0, \n",
    "                  os.path.join('experiments/fno_1/plots', f'FNO_1_{id}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fd76e-2db1-4c68-b133-cb79dc7c94b5",
   "metadata": {},
   "source": [
    "# The Plot for the FNO have been saved at `experiments/fno_1/plots/FNO_1_10.png`\n",
    "![CNO Output](experiments/fno_1/plots/FNO_1_10.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
